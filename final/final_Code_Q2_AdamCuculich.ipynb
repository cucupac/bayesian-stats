{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = np.loadtxt('problem2.csv', delimiter=',', skiprows=1)\n",
    "X1 = csv_data[:, 0]\n",
    "X2 = csv_data[:, 1]\n",
    "Y = csv_data[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha2, alpha1, alpha0, beta2, beta1, beta0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 00:11&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamcuculich/georgia-tech/bayesian-stats/env/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/adamcuculich/georgia-tech/bayesian-stats/env/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/adamcuculich/georgia-tech/bayesian-stats/env/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/adamcuculich/georgia-tech/bayesian-stats/env/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 16 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    # Data\n",
    "    x1_data = pm.Data(\"x1_data\", X1)\n",
    "    x2_data = pm.Data(\"x2_data\", X2)\n",
    "    y_data = pm.Data(\"y_data\", Y)\n",
    "\n",
    "    # Priors\n",
    "    beta0 = pm.Normal('beta0', mu=0, sigma=100)\n",
    "    beta1 = pm.Normal('beta1', mu=0, sigma=100)\n",
    "    beta2 = pm.Normal('beta2', mu=0, sigma=100)\n",
    "    alpha0 = pm.Normal('alpha0', mu=0, sigma=100)\n",
    "    alpha1 = pm.Normal('alpha1', mu=0, sigma=100)\n",
    "    alpha2 = pm.Normal('alpha2', mu=0, sigma=100)\n",
    "    \n",
    "    # Linear Model\n",
    "    mu = beta0 + (beta1 * x1_data) + (beta2 * x2_data)\n",
    "\n",
    "    # Variance\n",
    "    sigma_squared = pm.math.exp(alpha0 + (alpha1 * x1_data) + (alpha2 * x2_data))\n",
    "\n",
    "    # Likelihood\n",
    "    y_likelihood = pm.Normal('y', mu=mu, sigma=pm.math.sqrt(sigma_squared), observed=y_data)\n",
    "\n",
    "    # Posterior Sampling\n",
    "    trace = pm.sample(11000, tune=1000, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta0</th>\n",
       "      <td>8.499</td>\n",
       "      <td>0.011</td>\n",
       "      <td>8.478</td>\n",
       "      <td>8.520</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27288.0</td>\n",
       "      <td>25935.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta1</th>\n",
       "      <td>2.990</td>\n",
       "      <td>0.016</td>\n",
       "      <td>2.957</td>\n",
       "      <td>3.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>29100.0</td>\n",
       "      <td>26848.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta2</th>\n",
       "      <td>0.019</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>36528.0</td>\n",
       "      <td>30710.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha0</th>\n",
       "      <td>-5.908</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-6.146</td>\n",
       "      <td>-5.665</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25263.0</td>\n",
       "      <td>26154.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha1</th>\n",
       "      <td>-0.165</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30318.0</td>\n",
       "      <td>28327.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha2</th>\n",
       "      <td>9.965</td>\n",
       "      <td>0.154</td>\n",
       "      <td>9.664</td>\n",
       "      <td>10.264</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>31467.0</td>\n",
       "      <td>28730.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean     sd  hdi_2.5%  hdi_97.5%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "beta0   8.499  0.011     8.478      8.520      0.000    0.000   27288.0   \n",
       "beta1   2.990  0.016     2.957      3.022      0.000    0.000   29100.0   \n",
       "beta2   0.019  0.050    -0.081      0.114      0.000    0.000   36528.0   \n",
       "alpha0 -5.908  0.123    -6.146     -5.665      0.001    0.001   25263.0   \n",
       "alpha1 -0.165  0.159    -0.477      0.148      0.001    0.001   30318.0   \n",
       "alpha2  9.965  0.154     9.664     10.264      0.001    0.001   31467.0   \n",
       "\n",
       "        ess_tail  r_hat  \n",
       "beta0    25935.0    1.0  \n",
       "beta1    26848.0    1.0  \n",
       "beta2    30710.0    1.0  \n",
       "alpha0   26154.0    1.0  \n",
       "alpha1   28327.0    1.0  \n",
       "alpha2   28730.0    1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace, hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Significance\n",
    "\n",
    "## Significance for the Mean\n",
    "Juding by the 95% credible interval ranges of the vairables, `beta0` and `beta1` have 95% credible intervals of `[8.478, 8.520]` and `[2.957, 3.022]`, respectively. These variables are statistically significant as these 95% credible interval ranges do not include 0. Moreover, they are narrow ranges, suggesting high confidence.\n",
    "\n",
    "## Significance for the Variance\n",
    "Juding by the 95% credible interval ranges of the vairables, `alpha0` and `alpha2` have 95% credible intervals of `[-6.146, -5.665]` and `[9.664, 10.264]`, respectively. These variables are statistically significant as these 95% credible interval ranges do not include 0. Moreover, they are narrow ranges, suggesting high confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior Mean Alpha0:  -5.90780793584607\n",
      "Posterior Mean Alpha1:  -0.16520765681015462\n",
      "Posterior Mean Alpha2:  9.965230118902843\n",
      "Max X1:  1.0\n",
      "Min X2:  0.0\n",
      "Minimized Variance in Data:  0.0023042141517580373\n"
     ]
    }
   ],
   "source": [
    "# Obtain the posterior mean of alpha0, alpha1, and alpha2\n",
    "posterior_mean_alpha0 = np.mean(trace.posterior.alpha0.values)\n",
    "posterior_mean_alpha1 = np.mean(trace.posterior.alpha1.values)\n",
    "posterior_mean_alpha2 = np.mean(trace.posterior.alpha2.values)\n",
    "\n",
    "# Obtain the max x1 value and min x2 value\n",
    "max_x1 = np.max(X1)\n",
    "min_x2 = np.min(X2)\n",
    "\n",
    "# Calculate the minimized variance\n",
    "minmized_variance = pm.math.exp(posterior_mean_alpha0 + (posterior_mean_alpha1 * max_x1) + (posterior_mean_alpha2 * min_x2))\n",
    "\n",
    "# Print the results\n",
    "print(\"Posterior Mean Alpha0: \", posterior_mean_alpha0)\n",
    "print(\"Posterior Mean Alpha1: \", posterior_mean_alpha1)\n",
    "print(\"Posterior Mean Alpha2: \", posterior_mean_alpha2)\n",
    "print(\"Max X1: \", max_x1)\n",
    "print(\"Min X2: \", min_x2)\n",
    "print(\"Minimized Variance in Data: \", minmized_variance.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimize the Variance\n",
    "\n",
    "Using the posterior means obtained above for `alpha0`, `alpha1`, and `alpha2`, the equation for variance is:\n",
    "\n",
    "`variance = pm.math.exp(-5.907 - 0.166 * x1 + 9.964 * x2)`\n",
    "\n",
    "## Theoretical Answer\n",
    "Based on this, the more negative the exponent, the lower the variance. In other words, as the the exponent tends toward negative infinity (`-∞`), the variance tends toward `0`. Since the `x1` coefficient is negative, the value of `x1` that contributes to reducing the variance the most is the largest possible `x1` value (the larger the value subtracted, the more negative the exponent). Since the `x2` coefficent is positive, the value of `x2` that contributes to lowering the variance most is the smallest possible `x2` value. Based on this, the `(x1, x2)` pair that (theoretically) mimizes variance is `(∞, -∞)`.\n",
    "\n",
    "## If Bounded By Values in Data (Just for Fun)\n",
    "Just for fun, the maximum `x1` value in the data 1.0 and the minmum `x2` value is `0.0`. If constrained by these values (which we are theroetically not constrined by), the variance for `[1.0, 0.0]` would be `0.002305`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
